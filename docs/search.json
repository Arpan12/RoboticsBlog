[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "RoboticsBlog",
    "section": "",
    "text": "Python and Numpy cheat sheet for DL\n\n\n\n\n\n\n\nDL\n\n\nCode\n\n\nPython\n\n\n\n\n\n\n\n\n\n\n\nJun 10, 2023\n\n\nArpan Pallar\n\n\n\n\n\n\n  \n\n\n\n\nPost With Code\n\n\n\n\n\n\n\nnews\n\n\ncode\n\n\nanalysis\n\n\n\n\n\n\n\n\n\n\n\nJun 10, 2023\n\n\nHarlow Malloc\n\n\n\n\n\n\n  \n\n\n\n\nPPO Implementation for Coders\n\n\n\n\n\n\n\nRL\n\n\nCode\n\n\nPython\n\n\n\n\n\n\n\n\n\n\n\nJun 10, 2023\n\n\nArpan Pallar\n\n\n\n\n\n\n  \n\n\n\n\nTensorFLow and Pytorch Cheat Sheet for RL\n\n\n\n\n\n\n\nRL\n\n\nCode\n\n\nPython\n\n\n\n\n\n\n\n\n\n\n\nJun 10, 2023\n\n\nArpan Pallar\n\n\n\n\n\n\n  \n\n\n\n\nWelcome To My Blog\n\n\n\n\n\n\n\nnews\n\n\n\n\n\n\n\n\n\n\n\nJun 7, 2023\n\n\nTristan O’Malley\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "About this blog"
  },
  {
    "objectID": "posts/post-with-code/index.html",
    "href": "posts/post-with-code/index.html",
    "title": "Post With Code",
    "section": "",
    "text": "This is a post with executable code.\n\n1 + 1\n\n[1] 2"
  },
  {
    "objectID": "posts/PPO Implementation for Coders/index.html",
    "href": "posts/PPO Implementation for Coders/index.html",
    "title": "PPO Implementation for Coders",
    "section": "",
    "text": "PPO is state of the art algorithm for DeepRL. We wont go in depth into theory but focus on implementation.\n\nPromise\nAfter reading till the end of the blog, you should be able to implement PPO for discrete action space based environments.\n\n\nTheory\nPPO is a policy gradient method\n\\(\\pi(u|x)\\to\\)our current policy. This in deep RL is usually approximate by a Neural Net called actor net\n\\(g(x_n,u_n)\\to\\) cost incurred, we get from the environment for taking action\n\\(V_\\pi(x) = g(x,\\pi(x)) + \\alpha*V_\\pi(x+1)\\) = value function for policy \\(\\pi\\) . This in deep RL is usually approximate by a Neural Net called Critic net\nif \\(J(\\theta) = V_\\pi(x_0)\\) approximate value function for an episode starting at x0 following policy \\(\\pi(\\theta)\\) ,We can decrease \\(J(\\theta)\\) by gradient descent \\(\\theta_{new} = \\theta - \\gamma*\\Delta J(\\theta)\\)\nso writing more mathematically\n\\(J(\\theta) = E_{u_n}\\sim \\pi_{\\theta}[\\sum_{n=0}^N\\alpha^n*g(x_n,u_n)]\\)\nwe are able to show(proof not important)\n\\(\\Delta_\\theta J(\\theta) = E[\\sum_{n=0}^N\\Psi_n\\Delta_nlog\\ \\pi(u_n|x_n,\\theta)]\\)\nwhich is similar to minimizing:\n\\(min_\\theta E[\\Psi_n*log\\ \\pi(u_n|x_n,|\\theta)]\\)\nThis is what we would use for actor loss and minimize. In Practice since we get rewards from the Env so we put a negative sign before \\(\\Psi_n\\) so that we maximize the reward gain\nFor critic loss we take \\(\\Delta t_d^2\\) where \\(t_d = g(x_n,u_n)+\\gamma*V(x_{n+1)}-V(x_n)\\)\nfor\n\nReInforce: \\(\\Psi_n = G_n = \\sum_{k=n}^N \\alpha^k * g(x_k,u_k)\\)\nReInforce with baseLine: \\(\\Psi_n = G_n-V(x_n)\\)\nActor-Critic: \\(\\Psi_n = g(x_n,u_n)+\\alpha*V(x_{n+1})-V(x_n)\\)\nPPO: \\(\\Psi_n = A_t = \\sum_{t=k}^N \\lambda *\\mu*( Q(x_n,u_n)-V(x_n))\\)\nwhere \\(Q(x_n,u_n) = g(x_n,u_n)+\\gamma*V({x_{n+1}})\\)\nbut for PPO we approximate the log gradient even further by \\(min_\\theta E[\\sum_{n=0}^N A_n\\frac{\\pi(u_n|x_n,Theta)}{\\pi(u_n| x_n,\\theta_{old})}]\\)\n\nFor PPO we generally clip the gradient by limiting between 1-\\(\\epsilon\\) and 1+\\(\\epsilon\\)\n\\(min_\\theta E[\\sum_{n=0}^N min(A_n\\ \\frac{\\pi(u_n|x_n,Theta)}{\\pi(u_n| x_n,\\theta_{old}},clip(\\frac{\\pi(u_n|x_n,Theta)}{\\pi(u_n| x_n,\\theta_{old}},1-\\epsilon,1+\\epsilon)A_n]\\)\nissue to address:\n\n1 + 1\n\n[1] 2\n\n\n\n\nImplementation\nBatches and How to generate them\ncompute the advantage\nloss function"
  },
  {
    "objectID": "posts/welcome/index.html",
    "href": "posts/welcome/index.html",
    "title": "Welcome To My Blog",
    "section": "",
    "text": "This is the first post in a Quarto blog. Welcome!\n\nSince this post doesn’t specify an explicit image, the first image in the post will be used in the listing page of posts."
  },
  {
    "objectID": "posts/TensorFlow and Pytorch Cheetsheet for RL/index.html",
    "href": "posts/TensorFlow and Pytorch Cheetsheet for RL/index.html",
    "title": "TensorFLow and Pytorch Cheat Sheet for RL",
    "section": "",
    "text": "This is a post with executable code.\n\n1 + 1\n\n[1] 2"
  },
  {
    "objectID": "posts/Python,Numpy cheat sheet for DL/index.html",
    "href": "posts/Python,Numpy cheat sheet for DL/index.html",
    "title": "Python and Numpy cheat sheet for DL",
    "section": "",
    "text": "numpy.zeros(shape, dtype=float, order=‘C’, *, like=None)\nReturn a new array of given shape and type, filled with zeros.\n\n\nParameters:\n\n\nshapeint or tuple of ints\n\nShape of the new array, e.g., (2, 3) or 2.\n\ndtypedata-type, optional\n\nThe desired data-type for the array, e.g., numpy.int8. Default is numpy.float64.\n\norder{‘C’, ‘F’}, optional, default: ‘C’\n\nWhether to store multi-dimensional data in row-major (C-style) or column-major (Fortran-style) order in memory.\n\nlikearray_like, optional\n\nReference object to allow the creation of arrays which are not NumPy arrays. If an array-like passed in as like supports the __array_function__ protocol, the result will be defined by it. In this case, it ensures the creation of an array object compatible with that passed in via this argument.\n\n\n\n\nnp.zeros(5)\narray([ 0.,  0.,  0.,  0.,  0.])  # default is numpy.float64\n&gt;&gt;&gt;np.zeros((5,), dtype=int) #if you want to create a 1D array\narray([0, 0, 0, 0, 0])\n\n&gt;&gt;&gt;np.zeros((5,1))\narray([[0.],\n       [0.],\n       [0.],\n       [0.],\n       [0.]])\n       \n       \n&gt;&gt;&gt;s = (2,2)\n&gt;&gt;&gt;np.zeros(s)\narray([[ 0.,  0.],\n       [ 0.,  0.]]\n       \n#Multi-dim array \n&gt;&gt; np.zeros((4,3,2))  #a row of 2 element repeated 3 times-&gt; 3*2 array-&gt;repeated 4 times to give 4*3*2 array\n\narray([[[0., 0.],\n        [0., 0.],\n        [0., 0.]],\n\n       [[0., 0.],\n        [0., 0.],\n        [0., 0.]],\n\n       [[0., 0.],\n        [0., 0.],\n        [0., 0.]],\n\n       [[0., 0.],\n        [0., 0.],\n        [0., 0.]]])"
  },
  {
    "objectID": "posts/Python,Numpy cheat sheet for DL/index.html#np.zeros",
    "href": "posts/Python,Numpy cheat sheet for DL/index.html#np.zeros",
    "title": "Python and Numpy cheat sheet for DL",
    "section": "",
    "text": "numpy.zeros(shape, dtype=float, order=‘C’, *, like=None)\nReturn a new array of given shape and type, filled with zeros.\n\n\nParameters:\n\n\nshapeint or tuple of ints\n\nShape of the new array, e.g., (2, 3) or 2.\n\ndtypedata-type, optional\n\nThe desired data-type for the array, e.g., numpy.int8. Default is numpy.float64.\n\norder{‘C’, ‘F’}, optional, default: ‘C’\n\nWhether to store multi-dimensional data in row-major (C-style) or column-major (Fortran-style) order in memory.\n\nlikearray_like, optional\n\nReference object to allow the creation of arrays which are not NumPy arrays. If an array-like passed in as like supports the __array_function__ protocol, the result will be defined by it. In this case, it ensures the creation of an array object compatible with that passed in via this argument.\n\n\n\n\nnp.zeros(5)\narray([ 0.,  0.,  0.,  0.,  0.])  # default is numpy.float64\n&gt;&gt;&gt;np.zeros((5,), dtype=int) #if you want to create a 1D array\narray([0, 0, 0, 0, 0])\n\n&gt;&gt;&gt;np.zeros((5,1))\narray([[0.],\n       [0.],\n       [0.],\n       [0.],\n       [0.]])\n       \n       \n&gt;&gt;&gt;s = (2,2)\n&gt;&gt;&gt;np.zeros(s)\narray([[ 0.,  0.],\n       [ 0.,  0.]]\n       \n#Multi-dim array \n&gt;&gt; np.zeros((4,3,2))  #a row of 2 element repeated 3 times-&gt; 3*2 array-&gt;repeated 4 times to give 4*3*2 array\n\narray([[[0., 0.],\n        [0., 0.],\n        [0., 0.]],\n\n       [[0., 0.],\n        [0., 0.],\n        [0., 0.]],\n\n       [[0., 0.],\n        [0., 0.],\n        [0., 0.]],\n\n       [[0., 0.],\n        [0., 0.],\n        [0., 0.]]])"
  },
  {
    "objectID": "posts/Python,Numpy cheat sheet for DL/index.html#get-and-set-numpy-array-value",
    "href": "posts/Python,Numpy cheat sheet for DL/index.html#get-and-set-numpy-array-value",
    "title": "Python and Numpy cheat sheet for DL",
    "section": "Get and Set Numpy Array Value",
    "text": "Get and Set Numpy Array Value\nx = np.zeros((4,3,2))\n#just like you would do in Python list or C array\nx[3][1][0]=1\nNegative Indexing"
  },
  {
    "objectID": "posts/Python,Numpy cheat sheet for DL/index.html#np.zeros_like",
    "href": "posts/Python,Numpy cheat sheet for DL/index.html#np.zeros_like",
    "title": "Python and Numpy cheat sheet for DL",
    "section": "np.zeros_like",
    "text": "np.zeros_like\n\nnumpy.zeros_like(a, dtype=None, order=‘K’, subok=True, shape=None)[source]\n\nReturn an array of zeros with the same shape and type as a given array.\n\nParameters:\n\n\naarray_like\n\nThe shape and data-type of a define these same attributes of the returned array.\n\ndtypedata-type, optional\n\nOverrides the data type of the result.\n\n\n\n\n\n\n&gt;&gt;&gt;x = np.arange(6)}\n&gt;&gt;&gt;x = x.reshape((2, 3))\n&gt;&gt;&gt;x\narray([[0, 1, 2],\n       [3, 4, 5]])\n&gt;&gt;&gt;np.zeros_like(x)\narray([[0, 0, 0],\n       [0, 0, 0]])"
  },
  {
    "objectID": "posts/Python,Numpy cheat sheet for DL/index.html#np.arange",
    "href": "posts/Python,Numpy cheat sheet for DL/index.html#np.arange",
    "title": "Python and Numpy cheat sheet for DL",
    "section": "np.arange",
    "text": "np.arange\n&gt;&gt;&gt;np.arange(6) # 1D array\narray([0, 1, 2, 3, 4, 5])"
  },
  {
    "objectID": "posts/Python,Numpy cheat sheet for DL/index.html#np.reshape",
    "href": "posts/Python,Numpy cheat sheet for DL/index.html#np.reshape",
    "title": "Python and Numpy cheat sheet for DL",
    "section": "np.reshape",
    "text": "np.reshape\n\nnumpy.reshape(a, newshape, order=‘C’)\n\nGives a new shape to an array without changing its data.\n\nParameters:\n\n\naarray_like\n\nArray to be reshaped.\n\nnewshapeint or tuple of ints\n\nThe new shape should be compatible with the original shape. If an integer, then the result will be a 1-D array of that length. One shape dimension can be -1. In this case, the value is inferred from the length of the array and remaining dimensions.\n\n\n\n\n&gt;&gt;&gt;a = np.arange(6).reshape((3, 2))}\n&gt;&gt;&gt;a       \n#notice it is row wise. It makes easier to visualize if you put all the element \n#in 1D row array. Then take start row wise rearrangement  \n\narray([[0, 1],\n       [2, 3],\n       [4, 5]])\n\n&gt;&gt;&gt;np.reshape(a, (2, 3)) # C-like index ordering\narray([[0, 1, 2],\n       [3, 4, 5]])\n       \n#there can be one -1 index meaning its dimention are infered from number of elements and remaining specified shape\n&gt;&gt;&gt;np.reshape(a, (3,-1))       # the unspecified value is inferred to be 2\narray([[1, 2],\n       [3, 4],\n       [5, 6]])"
  },
  {
    "objectID": "posts/Python,Numpy cheat sheet for DL/index.html#np.ones",
    "href": "posts/Python,Numpy cheat sheet for DL/index.html#np.ones",
    "title": "Python and Numpy cheat sheet for DL",
    "section": "np.ones:",
    "text": "np.ones:\neverything similar to np.zeros\nnp.ones((2, 1))\narray([[1.],\n       [1.]])"
  },
  {
    "objectID": "posts/Python,Numpy cheat sheet for DL/index.html#np-array-slices",
    "href": "posts/Python,Numpy cheat sheet for DL/index.html#np-array-slices",
    "title": "Python and Numpy cheat sheet for DL",
    "section": "np array slices",
    "text": "np array slices\nThe syntax of Python NumPy slicing is [start : stop : step]\n\nStart : This index by default considers as ‘0’\nstop : This index considers as a length of the array.\nstep : By default it is considered as ‘1’.\n\n#this is another way to create a numpy array\n&gt;&gt;&gt;arr = np.array([3, 5, 7, 9, 11, 15, 18, 22]) \n&gt;&gt;&gt; arr2 = arr[:5]\n# [ 3  5  7  9 11]\n&gt;&gt;&gt;arr2 = arr[-4:-2]\n# [11 15]\n&gt;&gt;&gt;arr2 = arr[::3]\n#[ 3  9 18]\n\n\narr = np.array([[3, 5, 7, 9, 11],\n               [2, 4, 6, 8, 10]])\n               \n\n# Use slicing a 2-D arrays\narr2 = arr[1:,1:3]  #2D array remains 2D array\n[[4 6]]\n\narr2 = arr[1,1:3] #2D array remains 1D array\n\n#now try solving this before looking at the solution\narr = np.array([[[3, 5, 7, 9, 11],\n                 [2, 4, 6, 8, 10]],\n                [[5, 7, 8, 9, 2],\n                 [7, 2, 3, 6, 7]]])\n               \narr2 = arr[0,1,0:2]\n[2 4]"
  },
  {
    "objectID": "posts/Python,Numpy cheat sheet for DL/index.html#np.eye",
    "href": "posts/Python,Numpy cheat sheet for DL/index.html#np.eye",
    "title": "Python and Numpy cheat sheet for DL",
    "section": "np.eye:",
    "text": "np.eye:\n\nnumpy.eye(N, M=None, k=0, dtype=&lt;class ‘float’&gt;, order=‘C’, *, like=None)\n\nReturn a 2-D array with ones on the diagonal and zeros elsewhere.\n\nParameters:\n\n\nNint\n\nNumber of rows in the output.\n\nMint, optional\n\nNumber of columns in the output. If None, defaults to N.\n\nkint, optional\n\nIndex of the diagonal: 0 (the default) refers to the main diagonal, a positive value refers to an upper diagonal, and a negative value to a lower diagonal.\n\ndtypedata-type, optional\n\nData-type of the returned array.\n\n\n\n\n\n\n&gt;&gt;&gt;np.eye(2, dtype=int)\narray([[1, 0],\n       [0, 1]])\n&gt;&gt;&gt; np.eye(3, k=1)\narray([[0.,  1.,  0.],\n       [0.,  0.,  1.],\n       [0.,  0.,  0.]])"
  },
  {
    "objectID": "posts/Python,Numpy cheat sheet for DL/index.html#reversedrangen",
    "href": "posts/Python,Numpy cheat sheet for DL/index.html#reversedrangen",
    "title": "Python and Numpy cheat sheet for DL",
    "section": "reversed(range(n))",
    "text": "reversed(range(n))\niterate in reverse ie. n-1,n-2,…0"
  },
  {
    "objectID": "posts/Python,Numpy cheat sheet for DL/index.html#np.random.shuffle",
    "href": "posts/Python,Numpy cheat sheet for DL/index.html#np.random.shuffle",
    "title": "Python and Numpy cheat sheet for DL",
    "section": "np.random.shuffle",
    "text": "np.random.shuffle\n\nrandom.shuffle(x)\n\nModify a sequence in-place by shuffling its contents.\nThis function only shuffles the array along the first axis of a multi-dimensional array. The order of sub-arrays is changed but their contents remains the same.\n\n\narr = np.arange(10)\n&gt;&gt;&gt; np.random.shuffle(arr)\n&gt;&gt;&gt; arr\n[1 7 5 2 9 4 3 6 0 8] # random\n\n# works for multi-D array also\n\narr = np.arange(9).reshape((3, 3))\nnp.random.shuffle(arr)\narr\narray([[3, 4, 5], # random\n       [6, 7, 8],\n       [0, 1, 2]])"
  },
  {
    "objectID": "posts/Python,Numpy cheat sheet for DL/index.html#numpy-axes",
    "href": "posts/Python,Numpy cheat sheet for DL/index.html#numpy-axes",
    "title": "Python and Numpy cheat sheet for DL",
    "section": "Numpy Axes",
    "text": "Numpy Axes\nfor a 2D array remember this figure\n\n&gt;&gt;&gt; np_array_2d = np.arange(0, 6).reshape([2,3])\n[[0 1 2]\n [3 4 5]]\n\n&gt;&gt;&gt;np.sum(np_array_2d, axis = 0) \narray([3, 5, 7])\n\n&gt;&gt;&gt;np.sum(np_array_2d, axis = 1) #2d array become 1D in either case \n\narray([3, 12])   # note its not array([[3],[12]])\n\n&gt;&gt;&gt; np_array_1s = np.array([[1,1,1],[1,1,1]])\narray([[1, 1, 1],\n       [1, 1, 1]])\n&gt;&gt;&gt; np_array_9s = np.array([[9,9,9],[9,9,9]])\narray([[9, 9, 9],\n       [9, 9, 9]])\n\n&gt;&gt;&gt; np.concatenate([np_array_1s, np_array_9s], axis = 0)\narray([[1, 1, 1],\n       [1, 1, 1],\n       [9, 9, 9],\n       [9, 9, 9]])\n\n&gt;&gt;&gt; np.concatenate([np_array_1s, np_array_9s], axis = 1)\narray([[1, 1, 1, 9, 9, 9],\n       [1, 1, 1, 9, 9, 9]])\n      \n# Be careful with 1D arrays are different. there is only 1 axis ie axis 0\n\n&gt;&gt;&gt; np_array_1s_1dim = np.array([1,1,1])\n&gt;&gt;&gt; np_array_9s_1dim = np.array([9,9,9])\n\n&gt;&gt;&gt; np.concatenate([np_array_1s_1dim, np_array_9s_1dim], axis = 0)\n\narray([1, 1, 1, 9, 9, 9])"
  }
]